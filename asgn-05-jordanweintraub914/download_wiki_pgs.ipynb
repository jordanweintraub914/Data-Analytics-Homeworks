{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "contemporary-basement",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "religious-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from time import sleep\n",
    "from requests_html import HTMLSession # HTMLSession is how requests_html loads requests\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-auckland",
   "metadata": {},
   "source": [
    "### Open wiki page with sp500 firms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-nickname",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "session = HTMLSession()\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "r = session.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-rouge",
   "metadata": {},
   "source": [
    "### Creating input and text files folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-library",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#where to put sample firm data and text files...\n",
    "os.makedirs('inputs',exist_ok=True) #create input folder\n",
    "os.makedirs('text_files',exist_ok=True)#create folder for text files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-newport",
   "metadata": {},
   "source": [
    "### Get url to S&P500 firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "social-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get url to S&P500 firms\n",
    "table = r.html.find('#constituents')[0]\n",
    "rows = table.find('tr')[1:]\n",
    "urls = []\n",
    "for row in rows:\n",
    "    a_url = list(row.find('td')[1].absolute_links)[0]\n",
    "    urls.append(a_url)\n",
    "#     grab the link in the second column?\n",
    "\n",
    "\n",
    "#saving wiki sp500 table (with urls)\n",
    "(\n",
    "    pd.read_html(url)[0]\n",
    "    .assign(url=urls) #adding urls to variable called url\n",
    "    .to_csv('inputs/sp500_with_url.csv',index=False)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-elevation",
   "metadata": {},
   "source": [
    "## Download Their Wiki Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "blank-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Zoetis'\n",
    "save_to = 'text_files/ZTS.html'\n",
    "\n",
    "def download(get_url,put_here):\n",
    "    if not os.path.exists(put_here):\n",
    "        try:\n",
    "            urllib.request.urlretrieve(get_url, put_here)\n",
    "            r = requests.get(get_url)\n",
    "        except:\n",
    "            print('DOWNLOAD FAILED ON: ', get_url)\n",
    "        else:\n",
    "            #save results, typically save raw source\n",
    "            sleep(3) #makes it easier for server to run\n",
    "\n",
    "    \n",
    "    \n",
    "download(url,save_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alert-palestinian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOWNLOAD FAILED ON:  https://en.wikipedia.org/w/index.php?title=Pool_Corporation&action=edit&redlink=1\n"
     ]
    }
   ],
   "source": [
    "#loop over sample firms, download wiki page \n",
    "\n",
    "#read in the csv... assign it to dataframe\n",
    "sp500 = pd.read_csv('inputs/sp500_with_url.csv')\n",
    "sp500\n",
    "\n",
    "\n",
    "for index, row in sp500     .iterrows():\n",
    "    url = row['url']\n",
    "    save_to = 'text_files/' +row['Symbol'] + '.html'\n",
    "\n",
    "    download(url, save_to )\n",
    "    #download(row['url'], 'text_files/' +row['Symbol'] + '.html')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
