# Grading rubrics

## How we will grade the assignment

- Readme: 10%
    - Is it informative and professional?
    - Did they change the title of it?
    - Does it clearly describe the purpose of this repo?
	- How many grammar or formatting errors are there? (0 or 1, 2 or more)
- Python file: 85%
	- When you look at the python file _**in the repo online,**_ can you see the outputs from the code? (Y/N)
	- Are those outputs numbered consecutively from 1 upwards? (Y/N) , and put no if you can't see the output online. 
	- GRADER: clone this repo to your computer and run the file. Did it run without error? (Y/N)
	- Q1, Q4-Q10: correct?
    - Q2 and Q3: following the textbook, and quality of documentation of dataset issues
- gitignore: 5%
	- The online repo should only have these files: .gitignore, README.md, instructions/instructions.md, instructions/rubric.md, and asgn02exercises.ipynb (Y/N)
	- Did they modify `.gitignore` to include an auxilliary files produced when they worked on the code?
- Reviewer remarks (be nice - the spirit is learning collaboratively!)
	- Add some specific praise or describe something you learned
	- Do you have any constructive criticism?
	- If you think they struggled with part of the homework, share what you know about it that might help them. 
	
## How we will grade the peer review 

1. Accuracy and honor code: 80% 
	- We check 25% of peer reviews at random. Errors in reviews will reduce your peer evaluation grade 
	- If your review is materially wrong, we will audit all of your reviews for the semester and adjust those grades and yours accordingly. 
	- We will also check reviews if your reviewee thinks your review is materially wrong, mean spirited, or if we are told of academic honest violations. 
2. Feedback quality on remarks: 20%
