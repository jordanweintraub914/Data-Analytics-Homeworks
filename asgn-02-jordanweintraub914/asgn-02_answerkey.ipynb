{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `pandas` to explore firm accounting data\n",
    "\n",
    "I've given you a list of firms from 2020 with variables\n",
    "- \"gvkey\", \"lpermno\", \"lpermno\" = different datasets use different identifiers for firms\n",
    "- \"fyear\" = the fiscal year the remaining variable apply to \n",
    "- \"gsector\" = gsector, an industry classification (see [the wiki article on GICS](https://en.wikipedia.org/wiki/Global_Industry_Classification_Standard))\n",
    "- \"state\" = of headquarters\n",
    "- \"tic\" = ticker\n",
    "- various accounting statistics\n",
    "\n",
    "This data is a small slice of Compustat, which is a professional grade dataset that contains accounting data from SEC filings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'eda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e0375757db10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0meda\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minsufficient_but_starting_eda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_datareader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpdr\u001b[0m  \u001b[0;31m# to install: !pip install pandas_datareader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'eda'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from eda import insufficient_but_starting_eda\n",
    "import pandas_datareader as pdr  # to install: !pip install pandas_datareader\n",
    "from datetime import datetime\n",
    "\n",
    "# this file can be found here: https://github.com/LeDataSciFi/ledatascifi-2021/tree/main/data\n",
    "# if you click on the file, then \"raw\", you'll be at this url\n",
    "# which contains the raw data \n",
    "# and pandas can download/load it without saving it locally!\n",
    "url = 'https://raw.githubusercontent.com/LeDataSciFi/ledatascifi-2021/main/data/firms2020.csv'\n",
    "firms_df = pd.read_csv(url) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - create variables\n",
    "\n",
    "Create three variables:\n",
    "1. $log(sales)$\n",
    "2. $leverage = (dlc+dltt)/at $\n",
    "3. $capx\\_ratio = capx/at$\n",
    "\n",
    "Q1: Then `.describe()` these three variables right after creating them. (Don't do any cleaning yet! This is just a way for graders to check your definitions quickly.)\n",
    "\n",
    "Insert cell(s) below this one as needed to finish this Part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firms_df = \n",
    "import numpy as np\n",
    "firms_df = (firms_df\n",
    "            .assign(log_sale = np.log(firms_df['sale']), \n",
    "                    leverage = (firms_df['dlc']+firms_df['dltt'])/firms_df['at'],\n",
    "                    capx_ratio = firms_df['capx'] / firms_df['at']\n",
    "                   )            \n",
    "           )\n",
    "\n",
    "# will produce warning because obs with neg sales --> log(-#)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a rigorous project, we would have to make decisions about how to deal with observations with negative sales. \n",
    "\n",
    "In this dataset, the typical solution researchers make is to drop observations with missing or negative assets/sales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_desc = firms_df['log_sale','leverage','capx_ratio']\n",
    "firms_df[vars_to_desc].describe().T # the .T transposes the table to fit on screen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - EDA and data cleaning\n",
    "\n",
    "Q2: Implement the best practices from textbook section 3.2.5 for **the EDA dropdown and data cleaning dropdown.** \n",
    "\n",
    "Q3: After producing output, insert a markdown cell and summarize some possible issues you found. \n",
    "\n",
    "Note: You should **NOT** change any values here - you're just looking for issues to consider.\n",
    "\n",
    "Insert cell(s) below this one as needed to finish this Part.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "\n",
    "### Q2 - My work - EDA best practices\n",
    "\n",
    "The code below only shows 10 rows (`head.()` + `tail()`). That's simply not enough. \n",
    "\n",
    "In addition to the below code, I looked at the dataset using\n",
    "\n",
    "1. Random sampling of obs\n",
    "\n",
    "    ```python\n",
    "    firms_df[vars_to_desc].sample(50) # picks 50 random rows, rerun to see diff parts\n",
    "    ```\n",
    "    \n",
    "2. Look at chunks - it's useful to see sequential rows\n",
    "\n",
    "    ```python\n",
    "    firms_df[vars_to_desc][115:135] # change the row numbers to see diff parts\n",
    "    ```\n",
    "    \n",
    "3. Randomly pick N firms and pull all their observations:\n",
    "    ```python\n",
    "    list_of_firms = firms_df['tic'].unique() \n",
    "    rand_firms = np.random.choice(list_of_firms,5) \n",
    "    firms_df[vars_to_desc].query('tic in @rand_firms')\n",
    "    ```\n",
    "    \n",
    "Discussion is below.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_desc = ['GVKEY','tic','fyear', # firm/yr ids\n",
    "                'state','gsector',     # cat descriptors of firm\n",
    "                'log_sale','leverage','capx_ratio', # our vars\n",
    "                'sale','at','dlc','dltt','capx']    # underlying vars\n",
    "insufficient_but_starting_eda(firms_df[vars_to_desc],['state','gsector','fyear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are\",len(firms_df),\"obs in the firm data\",\n",
    "      \"covering\",firms_df['tic'].nunique(),\"unique tickers and \",\n",
    "      firms_df['GVKEY'].nunique(),\"unique GVKEYs.\"      \n",
    "     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 - Data summary and issues to think about\n",
    "\n",
    "#### Info on the sample, the data's unit level\n",
    "\n",
    "This dataset has accounting data on firms. It *appears* that GVKEY, LPERMNO, LPERMCO, and TIC are unique firm identifiers. There is also a firm name variable. \n",
    "\n",
    "Each firm has data for a given fiscal year, reported by FYEAR, and the reporting date is the `datadate` variable. \n",
    "\n",
    "**THE \"UNIT\" LEVEL FOR THIS DATASET IS FIRM YEAR even though the dataset we have only has 2020 observations.** \n",
    "\n",
    "#### Variables\n",
    "\n",
    "1. There are 56 \"states\"?\n",
    "2. Gsector is \"number\" but the numbers correspond to industry categories. It's a CATEGORICAL variable. \n",
    "3. Some observations have negative sales (and thus undefined logs). Will need to deal with that. \n",
    "4. Missing values - We have roughly 1230 observations with most variables. Should we restrict to these? But even in this subset, about 25% have no CAPX data. If those missing values should be zero, let's set it to zero. We should look into this...\n",
    "    - I usually set R&D and CAPX to 0 if missing. \n",
    "    - Then I drop observations where this choice causes the sources/uses of cash flow identity ($0=Inv + Ch_Cash + Div - Ch_Eqty - Ch_Debt - CF$) to fail). Checking this is a bit involved, so I'm skipping it. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Subsample analysis\n",
    "\n",
    "Let's explore how firms vary by state and industry. There are a lot of combinations of state-industry, so for simplicity let's only look at a few of them. \n",
    "\n",
    "So first **filter the data so you only have firms from California and Pennsylvania; and from the finance and industrial sectors**.\n",
    "\n",
    "Q4: Produce the following statistics **for all four combinations of state-industry we're left with (CA-finance, CA-industry, PA-finance, and PA-industry):**\n",
    "- the number of observations\n",
    "- the number of unique firms (use a different function than `count` or `len`)\n",
    "- the distribution of log(sales): mean, std, min, max\n",
    "\n",
    "\n",
    "\n",
    "Q5: Which of the four state-industries has the largest firms on average, as measured by assets (the $at$ variable)?\n",
    "\n",
    "Insert cell(s) below this one as needed to finish this Part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Q4 - My work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'firms_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ede8f9c985fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubsample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirms_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'state in [\"CA\",\"PA\"] & gsector in [\"40\",\"20\"]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# fun trick: display > print for prettyness of DFs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m display(subsample.pivot_table(index='gsector',columns='state',\n\u001b[1;32m      5\u001b[0m                    values='GVKEY',aggfunc=['count','nunique'])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'firms_df' is not defined"
     ]
    }
   ],
   "source": [
    "subsample = firms_df.query('state in [\"CA\",\"PA\"] & gsector in [\"40\",\"20\"]') \n",
    "# fun trick: display > print for prettyness of DFs\n",
    "\n",
    "display(subsample.pivot_table(index='gsector',columns='state',\n",
    "                   values='GVKEY',aggfunc=['count','nunique'])\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of observations is the same as the number of firms because there is only one year of data per firm in this subsample. \n",
    "\n",
    "Let's look at the distribution of log sales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subsample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f2c4bb2f1b28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m display(subsample\n\u001b[0m\u001b[1;32m      2\u001b[0m       .pivot_table(index='gsector',columns='state',\n\u001b[1;32m      3\u001b[0m                    values='log_sale',aggfunc=['describe'])\n\u001b[1;32m      4\u001b[0m       \u001b[0;31m# this is tough to read... lets make it less wide:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'subsample' is not defined"
     ]
    }
   ],
   "source": [
    "display(subsample\n",
    "      .pivot_table(index='gsector',columns='state',\n",
    "                   values='log_sale',aggfunc=['describe'])\n",
    "      # this is tough to read... lets make it less wide:  \n",
    "      .stack()\n",
    "      # then reorder the columns  \n",
    "      .droplevel(0, axis=1)\n",
    "      .reindex(columns=['count','mean','sd','min','25%','50%','75%','max'] )\n",
    "      # too many decimals! change the print format  \n",
    "      .style.format(\"{:.2f}\")\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5 - My work\n",
    "\n",
    "California finance (`gsector` = 40) firms are the largest on average in this subsample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subsample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8e5519022a35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubsample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gsector'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'at'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'subsample' is not defined"
     ]
    }
   ],
   "source": [
    "subsample.pivot_table(index='gsector',columns='state',values='at').style.format(\"{:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Covid stock returns\n",
    "\n",
    "For this part, use the firms in the subsample from part 3. \n",
    "\n",
    "Get their tickers from the data. Then copy relevant parts of  `stock_prices.ipynb` here and modify it so that\n",
    "- it uses the firms in the subsample from part 3\n",
    "- downloads stock prices from Feb 1 2020 to Apr 30 2020\n",
    "- HINT: I was able to download prices for 57 firms. \n",
    "\n",
    "Then, compute daily returns for each firm.\n",
    "\n",
    "Now we are ready for some questions: \n",
    "- Q6: Output `.describe()` for the return variable. \n",
    "    - HINT: put the returns for all firms in one variable (as opposed to having 57 return variables, one for each firm)\n",
    "- Q7: Compute and report the average return each day for each state-industry (so for each day, you now have 4 returns - one for CA-finance firms, and so on...)\n",
    "    - HINT: You'll need to merge the state and industry variables with the stock return data. \n",
    "    - HINT: `pd.merge()`\n",
    "    - HINT: We will talk more about merging in future weeks, but [the top voted answer here is pretty good](https://stackoverflow.com/questions/53645882/pandas-merging-101).\n",
    "- Q8: Compute the volatility for each firm, then take the average within each state-industry: Which industry-state had the lowest and highest average volatility? \n",
    "- Compute the **weekly** returns for each state-industry and answer \n",
    "    - Q9a: Which industry-state had the best single week in this time frame?\n",
    "    - Q9b: Which industry-state had the worst single week in this time frame?\n",
    "    - HINT: $r[M-F]=(1+r_M)*...*(1+r_F)-1$\n",
    "- Q10: Plot the weekly returns for for each state-industry\n",
    "\n",
    "Insert cell(s) below this one as needed to finish this Part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### My work\n",
    "\n",
    "Let's start by downloading the stock prices and reformatting the data to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subsample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f869c1f1a058>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mstock_prices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data_yahoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mstock_prices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstock_prices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Adj Close'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# reduce to just columns with this in the name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mstock_prices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubsample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# put their tickers as column names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'subsample' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas_datareader as pdr  # to install: !pip install pandas_datareader\n",
    "from datetime import datetime\n",
    "\n",
    "start = datetime(2020, 2, 1)\n",
    "end = datetime(2020, 4, 30)\n",
    "\n",
    "# load\n",
    "stock_prices = pdr.get_data_yahoo(subsample['tic'].to_list(), start=start, end=end)\n",
    "stock_prices = stock_prices.filter(like='Adj Close') # reduce to just columns with this in the name\n",
    "stock_prices.columns = subsample['tic'].to_list() # put their tickers as column names\n",
    "stock_prices = stock_prices.stack().swaplevel().sort_index().reset_index()\n",
    "stock_prices.columns = ['Firm','Date','Adj Close']\n",
    "stock_prices['ret'] = stock_prices.groupby('Firm')['Adj Close'].pct_change()\n",
    "\n",
    "# add state + gsector variables\n",
    "stock_prices= stock_prices.merge(subsample[['tic','gsector','state']],left_on='Firm',right_on='tic')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6 - `.describe()` returns in the sample\n",
    "\n",
    "We've already formatted the data. Just output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prices['ret'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7 - Compute portfolio returns and average over sample period\n",
    "\n",
    "First we need to compute the portfolio returns for each day. Here, our portfolios are equally weighted baskets of all the firms in a given state and industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_port_ret = (stock_prices\n",
    "                  .groupby(['state','gsector','Date']) # for each portfolio, for each day\n",
    "                  ['ret'].mean()                       # avg the return for that day for the firms in the port\n",
    "                  .reset_index()                       # you can work with state/sector/date as index or vars\n",
    "                                                       # I decided to convert them to variables and sort                                                    \n",
    "                  .sort_values(['state','gsector','Date'])\n",
    "                 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 1:\n",
    "daily_port_ret.groupby(['state','gsector'])['ret'].mean()\n",
    "\n",
    "# option 2:\n",
    "daily_port_ret.pivot_table(index='gsector',columns='state',values='ret')\n",
    "\n",
    "# option 2+formatting\n",
    "(daily_port_ret.pivot_table(index='gsector',columns='state',values='ret')\n",
    " .multiply(100) # these are now percentages!!!\n",
    ".style.format(\"{:.3f}%\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8 - California Industrials were most volatile over this period\n",
    "\n",
    "Here I use the `std`, but the conclusion is the same with `var`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stock_prices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-02d5c641fdf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m (stock_prices\n\u001b[0m\u001b[1;32m      2\u001b[0m  \u001b[0;31m# compute std for each firm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m  \u001b[0;31m# I added state/sector to the groupby JUST to keep those vars around\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m  \u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'gsector'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ret'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m  \u001b[0;31m# now, we have 3 index vars. groupby on index vars by adding \"level=\" inside groupby\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stock_prices' is not defined"
     ]
    }
   ],
   "source": [
    "(stock_prices\n",
    " # compute std for each firm\n",
    " # I added state/sector to the groupby JUST to keep those vars around\n",
    " .groupby(['state','gsector','tic'])['ret'].std()   \n",
    " # now, we have 3 index vars. groupby on index vars by adding \"level=\" inside groupby\n",
    " # and we have a single Series var (without a name) so we just take a mean\n",
    " .groupby(level=['state','gsector']).mean()\n",
    ") \n",
    "\n",
    "(stock_prices\n",
    " \n",
    " .groupby(['state','gsector','tic'])['ret'].std()  .groupby(level=['state','gsector']).mean()\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9 - Compute weekly returns for the portfolios\n",
    "\n",
    "The biggest challenge is compounding the returns. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to compound returns\n",
    "\n",
    "Let $r_t = (P_t+D_t)/P_{t-1}$ be the simple return for a single period with dividends included. \n",
    "\n",
    "Let $R_t = (1+r_t)$ be the **gross** (thus, the capital \"R\") return for a single period.\n",
    "\n",
    "Then the gross return for a number of periods is\n",
    "\n",
    "\\begin{equation}\n",
    "R[0,T] = \\prod_{t=1}^T R_t\n",
    "\\end{equation}\n",
    "\n",
    "and the return for the same set of periods is simply the above minus 1.\n",
    "\n",
    "\\begin{align}\n",
    "r[0,T] = & R[0,T] - 1  \\\\\n",
    "= & (\\prod_{t=1}^T R_t) - 1\n",
    "\\end{align}\n",
    "\n",
    "There is one more way to compute the gross return: \"Sum the log returns, then exponentiate\":\n",
    "\n",
    "\\begin{align}\n",
    "R[0,T] = & \\prod_{t=1}^T R_t \\\\\n",
    "       = & \\prod_{t=1}^T ( e(ln( R_t))        ) \\\\\n",
    "       = & e(\\sum_{t=1}^T ln(R_t)) \\\\\n",
    "\\end{align}\n",
    "the second line works because $e(ln(x))=x$ and the last line works because $e^a*e^b*e^c=e^{a+b+c}$.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_port_ret = (daily_port_ret\n",
    "                   # compute gross returns for each asset (and get the week var)\n",
    "                   .assign(R = 1+daily_port_ret['ret'],\n",
    "                           week = daily_port_ret['Date'].dt.isocalendar().week)\n",
    "                   # for each portfolio and week...\n",
    "                   .groupby(['state','gsector','week'])\n",
    "                   # cumulate the returns\n",
    "                   ['R'].prod()\n",
    "                   # subtract one\n",
    "                   -1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The best and worst weeks belonged to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\n-------------------------\\nThe BEST week in this sample was:\\n-------------------------')\n",
    "print(weekly_port_ret.nlargest(1))\n",
    "print('\\n\\n-------------------------\\nThe WORST week in this sample was::\\n-------------------------')\n",
    "print(weekly_port_ret.nsmallest(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weekly_port_ret' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-e5e61c37c50c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ugly but quick\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mweekly_port_ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mweekly_port_ret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weekly_port_ret' is not defined"
     ]
    }
   ],
   "source": [
    "# ugly but quick\n",
    "weekly_port_ret\n",
    "weekly_port_ret.unstack().T.plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
